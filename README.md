# ğŸ¤– IngestÃ£o e Busca SemÃ¢ntica com LangChain e PostgreSQL

Sistema de RAG (Retrieval-Augmented Generation) que permite fazer ingestÃ£o de documentos PDF e realizar buscas semÃ¢nticas com respostas baseadas exclusivamente no conteÃºdo dos documentos.

## ğŸ“‹ Funcionalidades

- **IngestÃ£o de PDF**: LÃª arquivos PDF e armazena em banco vetorial PostgreSQL com pgVector
- **Busca SemÃ¢ntica**: Encontra informaÃ§Ãµes relevantes usando embeddings
- **Chat Interativo**: Interface CLI para fazer perguntas sobre o conteÃºdo do PDF
- **Respostas Contextualizadas**: Respostas baseadas apenas no conteÃºdo do documento

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.10+**
- **LangChain** - Framework para aplicaÃ§Ãµes com LLM
- **PostgreSQL + pgVector** - Banco de dados vetorial
- **Google Gemini** - Embeddings e LLM
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o do banco

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ docker-compose.yaml   # ConfiguraÃ§Ã£o PostgreSQL + pgVector
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â”œâ”€â”€ .env.example         # Template das variÃ¡veis de ambiente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py        # Script de ingestÃ£o do PDF
â”‚   â”œâ”€â”€ search.py        # MÃ³dulo de busca semÃ¢ntica
â”‚   â””â”€â”€ chat.py          # Interface CLI interativa
â”œâ”€â”€ investimentos.pdf            # Documento PDF para ingestÃ£o
â””â”€â”€ README.md           # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd desafioLangchain
```

### 2. Criar Ambiente Virtual

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar VariÃ¡veis de Ambiente

Copie o arquivo `.env.example` para `.env` e configure suas chaves:

```bash
cp .env.example .env
```

Edite o arquivo `.env`:

```env
# ConfiguraÃ§Ãµes do Banco de Dados PostgreSQL
PGVECTOR_URL=postgresql://postgres:postgres@localhost:5432/rag
PGVECTOR_COLLECTION=pdf_documents

# API Key do Google Gemini
GOOGLE_API_KEY=sua_api_key_do_gemini_aqui
```

### 5. Obter API Key do Google Gemini

1. Acesse [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crie uma nova API Key
3. Cole a chave no arquivo `.env`

## ğŸ³ Executando o Sistema

### 1. Subir o Banco de Dados

```bash
docker compose up -d
```

Isso irÃ¡:
- Subir PostgreSQL com extensÃ£o pgVector
- Configurar PgAdmin (opcional) em http://localhost:8081
- Criar a extensÃ£o vector automaticamente

### 2. Executar IngestÃ£o do PDF

```bash
python src/ingest.py
```

Este comando irÃ¡:
- Carregar o arquivo `investimentos.pdf`
- Dividir em chunks de 1000 caracteres (overlap 150)
- Gerar embeddings usando Gemini
- Armazenar no banco vetorial PostgreSQL

### 3. Iniciar o Chat Interativo

```bash
python src/chat.py
```

## ğŸ’¬ Exemplos de Uso

### Perguntas Dentro do Contexto
```
FaÃ§a sua pergunta: Qual o faturamento da empresa?
ğŸ” Buscando informaÃ§Ãµes...
ğŸ“‹ RESPOSTA: O faturamento foi de 10 milhÃµes de reais.
```

### Perguntas Fora do Contexto
```
FaÃ§a sua pergunta: Qual Ã© a capital da FranÃ§a?
ğŸ” Buscando informaÃ§Ãµes...
ğŸ“‹ RESPOSTA: NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.
```

## ğŸ”§ Testando Componentes Individualmente

### Testar Busca SemÃ¢ntica
```bash
python src/search.py
```

### Verificar ConexÃ£o com Banco
```bash
docker exec -it postgres_rag_desafio psql -U postgres -d rag -c "\dt"
```

## ğŸ“Š Monitoramento

### PgAdmin (Opcional)
- URL: http://localhost:8081
- Email: admin@admin.com
- Senha: admin

### Logs do Docker
```bash
docker compose logs -f postgres
```

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajustar ParÃ¢metros de Busca

No arquivo `src/search.py`, vocÃª pode modificar:

```python
# NÃºmero de resultados retornados (padrÃ£o: 10)
results = self.store.similarity_search_with_score(query, k=10)
```

### Ajustar Chunking

No arquivo `src/ingest.py`:

```python
splits = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Tamanho do chunk
    chunk_overlap=150     # SobreposiÃ§Ã£o entre chunks
)
```

### Trocar Modelo de LLM

No arquivo `src/chat.py`:

```python
self.llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # Ou outro modelo
    temperature=0,             # Criatividade (0-1)
)
```

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de ConexÃ£o com Banco
```bash
# Verificar se containers estÃ£o rodando
docker compose ps

# Reiniciar containers
docker compose down && docker compose up -d
```

### Erro de API Key
```bash
# Verificar se variÃ¡veis estÃ£o carregadas
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('GOOGLE_API_KEY'))"
```

### Erro de DependÃªncias
```bash
# Reinstalar dependÃªncias
pip install --upgrade -r requirements.txt
```

## ğŸ“ Requisitos Atendidos

- âœ… **IngestÃ£o**: PDF dividido em chunks de 1000 caracteres com overlap de 150
- âœ… **Embeddings**: Usando `models/embedding-001` do Gemini
- âœ… **Banco Vetorial**: PostgreSQL com pgVector
- âœ… **Busca**: `similarity_search_with_score(query, k=10)`
- âœ… **LLM**: Gemini 1.5 Flash para respostas
- âœ… **Prompt Template**: Implementado conforme especificaÃ§Ã£o
- âœ… **CLI**: Interface interativa no terminal
- âœ… **Docker**: PostgreSQL rodando em container

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido como parte do desafio de IngestÃ£o e Busca SemÃ¢ntica com LangChain e PostgreSQL.

---

**ğŸš€ Pronto para usar! Execute os comandos na ordem e comece a fazer perguntas sobre seu PDF!**
